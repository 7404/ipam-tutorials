{
 "metadata": {
  "name": "2_2_mlp"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Multilayer Perceptron\n",
      "=====================\n",
      "\n",
      "In the previous tutorial on linear SVMs, we looked at how training a model\n",
      "consists in defining a training objective, and then minimizing it with respect\n",
      "to model parameters by either stochastic or batch gradient descent.\n",
      "\n",
      "In this tutorial we will augment our SVM with _internal layers_ of _hidden\n",
      "units_ and turn our linear classifier into a deep (multi-layer) architecture.\n",
      "\n",
      "An MLP can be viewed as an SVM, where the input $\\mathbf{x}$ is first transformed using a\n",
      "learnt non-linear vector-valued transformation $\\Phi$.\n",
      "The purpose of this transformation is to map the input data into a space where it becomes linearly separable.\n",
      "The vector $\\Phi(\\mathbf{x})$ is referred to as a _hidden layer_.\n",
      "\n",
      "This tutorial will again tackle the problem of MNIST digit classification.\n",
      "XXX"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# XXX imports"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## The MLP Model\n",
      "\n",
      "Typically the function $\\Phi$ is taken to be the function\n",
      "$\\mathbb{R}^{D_0} \\rightarrow (-1, 1)^{D_1}$\n",
      "\n",
      "$$\n",
      "\\Phi(\\mathbf{x}; V, \\mathbf{c}) = \\tanh( \\mathbf{x} V + \\mathbf{c})\n",
      "$$\n",
      "\n",
      "in which $V \\in \\mathbb{R}^{D_0 \\times D_1}$ is called a _weight matrix_, and\n",
      "$\\mathbf{c} \\in \\mathbb{R}^{D_1}$ is called a _bias vector_.\n",
      "The integer $D_0$ is the number of elements in $\\mathbf{x}$ (sometimes, number\n",
      "of \"input units\").\n",
      "The integer $D_1$ is the number of \"hidden units\" of the MLP.\n",
      "We abuse notation slightly here by using $\\tanh(\\mathbf{u})$ for a vector\n",
      "$\\mathbf{u}$ to denote\n",
      "the vector of values $\\tanh(\\mathbf{u}_i)$.\n",
      "Sometimes other non-linear scalar functions are used instead of the tanh\n",
      "function -- whichever one is used is called the _activation function_ of\n",
      "layer $\\Phi$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tanh_layer(V, c, x):\n",
      "    return np.tanh(np.dot(x, V) + c)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When combined with an SVM classifier (recall previous tutorial), the full classification model can be written\n",
      "\n",
      "$$\n",
      "    \\mathrm{MLP}(\\mathbf{x}) = \\mathrm{SVM}\\left(\\Phi(\\mathbf{x}; V, \\mathbf{c})); W, \\mathbf{b} \\right)\n",
      "$$\n",
      "\n",
      "This sort of MLP (or Artificial Neural Network - ANN) with a single hidden layer\n",
      "is sometimes represented graphically as follows:\n",
      "\n",
      "<img src=\"files/images/mlp.png\" align=center/>\n",
      "\n",
      "A single hidden layer of this form is sufficient to make the MLP a universal approximator.\n",
      "However we will see shortly\n",
      "that there are benefits to using many such hidden layers (deep learning).\n",
      "See these course notes for an\n",
      "[introduction to MLPs, the back-propagation algorithm, and how to train MLPs](http://www.iro.umontreal.ca/~pift6266/H10/notes/mlp.html)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define prediction function"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Training an MLP\n",
      "\n",
      "To train an MLP, we learn **all** parameters of the model ($W, \\mathbf{b}, V,\n",
      "\\mathbf{c}$) by gradient descent,\n",
      "just as we learned the parameters $W, \\mathbf{b}$ previously when training the\n",
      "SVM.\n",
      "\n",
      "\n",
      "The initial values for the weights of a hidden layer ($V$) should be uniformly\n",
      "sampled from a symmetric interval that depends on the activation function.\n",
      "For the tanh activation function results obtained in [Xavier10]_ show that the\n",
      "interval should be\n",
      "$$\n",
      "\\left[ -\\sqrt{\\frac{6}{D_0 + D_1}}, \\sqrt{\\frac{6}{D_0 + D_1}} \\right]\n",
      "$$\n",
      "\n",
      "For the logistic sigmoid function $1 / (1 + e^{-u})$ the interval is slightly\n",
      "different:\n",
      "\n",
      "$$\n",
      "\\left[ -4\\sqrt{\\frac{6}{D_0 + D_1}},4\\sqrt{\\frac{6}{D_0 + D_1}} \\right]\n",
      "$$.\n",
      "\n",
      "This initialization ensures that at least early in training, each neuron operates in a regime of its activation function where information can easily be propagated both upward (activations flowing from inputs to outputs) and backward (gradients flowing from outputs to inputs)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# initialize W, b, V, c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As before, we train this model using stochastic gradient descent with\n",
      "mini-batches. The difference is that we modify the cost function to include the\n",
      "regularization term. `L1_reg` and `L2_reg` are the hyperparameters\n",
      "controlling the weight of these regularization terms in the total cost function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SGD minimization as in SVM"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# L-BFGS minimization as in SVM"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This code should run for XXX seconds and produce a score of XXX.\n",
      "\n",
      "XXX Summary"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercises\n",
      "\n",
      "Try the following exercises out to get a better feel for training MLPs."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise: Breaking symmetry\n",
      "\n",
      "It might seem more natural to initialize all of the MLP parameters to $0$.\n",
      "What goes wrong when you do this?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise: SGD vs. L-BFGS\n",
      "\n",
      "We've talked about using SGD as a pre-conditioner, but what exactly does that mean?\n",
      "Try running L-BFGS starting from the original random initialization -- how good does it get on train and test, and how long does it take to find a solution.\n",
      "\n",
      "Now repeat that with various amounts of SGD before the L-BFGS. What happens?\n",
      "\n",
      "Now raise the number of examples seen per iteration of SGD. How does this affect the convergence of SGD and its value as a pre-conditioner?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Tips and Tricks for training MLPs\n",
      "\n",
      "There are several hyper-parameters in the above code, which are not (and,\n",
      "generally speaking, cannot be) optimized by gradient descent.\n",
      "The design of outer-loop algorithms for optimizing them is a topic of ongoing\n",
      "research.\n",
      "Over the last 25 years, researchers have devised various rules of thumb for choosing them.\n",
      "A very good overview of these tricks can be found in [Efficient\n",
      "BackProp](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf) by Yann LeCun,\n",
      "Leon Bottou, Genevieve Orr, and Klaus-Robert Mueller. Here, we summarize\n",
      "the same issues, with an emphasis on the parameters and techniques that we\n",
      "actually used in our code.\n",
      "\n",
      "### Tips and Tricks: Nonlinearity\n",
      "\n",
      "Which non-linear activation function should you use in a neural network?\n",
      "Two of the most common ones are the logistic sigmoid and the tanh functions.\n",
      "For reasons explained in [Section 4.4](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf), nonlinearities that\n",
      "are symmetric around the origin are preferred because they tend to produce\n",
      "zero-mean inputs to the next layer (which is a desirable property).\n",
      "Empirically, we have observed that the tanh has better convergence properties.\n",
      "\n",
      "\n",
      "### Tips and Tricks: Weight initialization\n",
      "\n",
      "At initialization we want the weights to be small enough around the origin\n",
      "so that the activation function operates near its linear regime, where gradients are\n",
      "the largest. Otherwise, the gradient signal used for learning is attenuated by\n",
      "each layer as it is propagated from the classifier towards the inputs.\n",
      "Other desirable properties, especially for deep networks,\n",
      "are to conserve variance of the activation as well as variance of back-propagated gradients from layer to layer.\n",
      "This allows information to flow well upward and downward in the network and\n",
      "reduces discrepancies between layers.\n",
      "The initialization used above represents a good compromise between these two\n",
      "constraints.\n",
      "For mathematical considerations, please refer to [Xavier10]_.\n",
      "\n",
      "\n",
      "### Tips and Tricks: Learning Rate\n",
      "\n",
      "Optimization by stochastic gradient descent is very sensitive to the step size or _learning rate_.\n",
      "There is a great deal of literature on how to choose a the learning rate, and how to change it during optimization.\n",
      "The simplest solution is to use a constant rate. Rule of thumb: try\n",
      "several log-spaced values ($10^{-1}, 10^{-2}, \\ldots$) and narrow the\n",
      "(logarithmic) grid search to the region where you obtain the lowest\n",
      "validation error.\n",
      "\n",
      "Decreasing the learning rate over time can help a model to settle down into a\n",
      "[local] minimum.\n",
      "One simple rule for doing that is $\\frac{\\mu_0}{1 + d\\times t}$ where\n",
      "$\\mu_0$ is the initial rate (chosen, perhaps, using the grid search\n",
      "technique explained above), $d$ is a so-called \"decrease constant\"\n",
      "which controls the rate at which the learning rate decreases (typically, a\n",
      "smaller positive number, $10^{-3}$ and smaller) and $t$ is the epoch/stage.\n",
      "\n",
      "[Section 4.7](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf) details\n",
      "procedures for choosing a learning rate for each parameter (weight) in our\n",
      "network and for choosing them adaptively based on the error of the classifier.\n",
      "\n",
      "### Tips and Tricks: Number of hidden units\n",
      "\n",
      "The number of hidden units that gives best results is dataset-dependent.\n",
      "Generally speaking, the more complicated the input distribution is, the more capacity the network\n",
      "will require to model it, and so the larger the number of hidden units thatwill be needed (note that the number of weights in a layer, perhaps a more direct\n",
      "measure of capacity, is $D_0\\times D_1$ (recall $D_0$ is the number of inputs and\n",
      "$D_1$ is the number of hidden units).\n",
      "\n",
      "Unless we employ some regularization scheme (early stopping or L1/L2\n",
      "penalties), a typical number of hidden  units vs. generalization performance graph will be U-shaped.\n",
      "\n",
      "### Tips and Tricks: Norm Regularization\n",
      "\n",
      "Typical values to try for the L1/L2 regularization parameter $\\lambda$ are $10^{-2}, 10^{-3}, \\ldots$.\n",
      "It can be useful to regularize the topmost layers in an MLP (closest\n",
      "to and including the classifier itself) to prevent them from overfitting noisy\n",
      "hidden layer features, and to encourage the features themselves to be more\n",
      "discriminative."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}